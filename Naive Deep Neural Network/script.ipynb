{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01c743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30192e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Gradient Descent \n",
    "\n",
    "\n",
    "class TwoLayerNetwork:\n",
    "    def __init__(self , input_size , hidden_size , output_size):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = np.random.randn(input_size , hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = np.random.randn(hidden_size , output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def forward(self , X):\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "\n",
    "        z1 = np.dot(X , W1) + b1\n",
    "        a1 = np.maximum(0 , z1) #Relu\n",
    "        z2 = np.dot(a1 , W2) + b2\n",
    "        exp_z = np.exp(z2)\n",
    "        probs = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        return probs\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        probs = self.forward(X)\n",
    "        correct_logprobs = -np.log(probs[range(len(X)), y])\n",
    "        data_loss = np.sum(correct_logprobs)\n",
    "        return 1.0/len(X) * data_loss\n",
    "    \n",
    "    def train(self , X , y , epochs , lr = 0.1):\n",
    "\n",
    "        for e in range(epochs):\n",
    "            z1 = np.dot(X, self.params['W1']) + self.params['b1']\n",
    "            a1 = np.maximum(0, z1)\n",
    "            z2 = np.dot(a1, self.params['W2']) + self.params['b2']\n",
    "            exp_z = np.exp(z2)\n",
    "            probs = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "            #Back prop\n",
    "            delta3 = probs\n",
    "            #delta3[range(len(X)) , y] = basically from delta3 chose the probabilites of predicted classes\n",
    "            delta3[range(len(X)) , y] -= 1\n",
    "            dw2 = np.dot(a1.T , delta3)\n",
    "            db2 = np.sum(delta3 , axis= 0)\n",
    "\n",
    "            delta2 = np.dot(delta3, self.params['W2'].T) * (a1 > 0) # derivative of ReLU\n",
    "            dw1 = np.dot(X.T , delta2)\n",
    "            db1 = np.sum(delta2)\n",
    "\n",
    "            self.params['W1'] -= lr * dw1\n",
    "            self.params['b1'] -= lr * db1\n",
    "            self.params['W2'] -= lr * dw2\n",
    "            self.params['b2'] -= lr * db2\n",
    "\n",
    "            # Print loss for monitoring training progressq\n",
    "            if e % 100 == 0:\n",
    "                loss = self.loss(X, y)\n",
    "                print(\"Epoch {}: loss = {}\".format(e, loss))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa950cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BatchGD:\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size=5):\n",
    "        self.params = {\n",
    "            'W1': np.random.randn(input_size, hidden_size) * 0.01,\n",
    "            'b1': np.zeros(hidden_size),\n",
    "            'W2': np.random.randn(hidden_size, output_size) * 0.01,\n",
    "            'b2': np.zeros(output_size)\n",
    "        }\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        W1, b1 = self.params['W1'], self.params['b1']\n",
    "        W2, b2 = self.params['W2'], self.params['b2']\n",
    "        z1 = np.dot(X, W1) + b1\n",
    "        a1 = np.maximum(0, z1)  # ReLU\n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))  # for numerical stability\n",
    "        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return probs, a1\n",
    "\n",
    "    def loss(self, X, y):\n",
    "        probs, _ = self.forward(X)\n",
    "        correct_logprobs = -np.log(probs[range(len(X)), y] + 1e-9)\n",
    "        data_loss = np.mean(correct_logprobs)\n",
    "        return data_loss\n",
    "\n",
    "    def train(self, X, y, epochs, lr=0.1):\n",
    "        num_samples = X.shape[0]\n",
    "\n",
    "        for i in range(epochs):\n",
    "            # Shuffle data\n",
    "            indices = np.arange(num_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "\n",
    "            for start_idx in range(0, num_samples, self.batch_size):\n",
    "                end_idx = min(start_idx + self.batch_size, num_samples)\n",
    "                X_batch = X[start_idx:end_idx]\n",
    "                y_batch = y[start_idx:end_idx]\n",
    "\n",
    "                x_mean = np.mean(X_batch , axis = 0)\n",
    "                y_mean = np.mean(y_batch , axis = 0)\n",
    "                x_std = np.std(X_batch , axis = 0)\n",
    "                y_std = np.std(y_batch , axis = 0)\n",
    "\n",
    "                X_batch = (X_batch - x_mean) / x_std\n",
    "                y_batch = (y_batch-y_mean) / y_std\n",
    "\n",
    "                # Forward pass\n",
    "                z1 = np.dot(X_batch, self.params['W1']) + self.params['b1']\n",
    "                a1 = np.maximum(0, z1)\n",
    "                z2 = np.dot(a1, self.params['W2']) + self.params['b2']\n",
    "                exp_scores = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
    "                probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "                # Backward pass\n",
    "                delta3 = probs\n",
    "                delta3[range(len(X_batch)), y_batch] -= 1\n",
    "                dw2 = np.dot(a1.T, delta3) / len(X_batch)\n",
    "                db2 = np.sum(delta3, axis=0) / len(X_batch)\n",
    "\n",
    "                delta2 = np.dot(delta3, self.params['W2'].T) * (a1 > 0)\n",
    "                dw1 = np.dot(X_batch.T, delta2) / len(X_batch)\n",
    "                db1 = np.sum(delta2, axis=0) / len(X_batch)\n",
    "\n",
    "                # Parameter update\n",
    "                self.params['W1'] -= lr * dw1\n",
    "                self.params['b1'] -= lr * db1\n",
    "                self.params['W2'] -= lr * dw2\n",
    "                self.params['b2'] -= lr * db2\n",
    "\n",
    "            # Print loss\n",
    "            if i % 100 == 0 or i == epochs - 1:\n",
    "                loss_val = self.loss(X, y)\n",
    "                print(f\"Epoch {i}: loss = {loss_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea4c8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 0.6972371790514336\n",
      "Epoch 100: loss = 0.07806268479878843\n",
      "Epoch 200: loss = 0.02323949071526986\n",
      "Epoch 300: loss = 0.012515676827851974\n",
      "Epoch 400: loss = 0.008348260706092903\n",
      "Epoch 500: loss = 0.006182881385986309\n",
      "Epoch 600: loss = 0.004880797184890369\n",
      "Epoch 700: loss = 0.0040124989477365305\n",
      "Epoch 800: loss = 0.003397674243222044\n",
      "Epoch 900: loss = 0.0029415241607864823\n",
      "Predictions:  [0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate a toy dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Initialize a neural network\n",
    "net = TwoLayerNetwork(input_size=2, hidden_size=10, output_size=2)\n",
    "\n",
    "# Train the neural network\n",
    "net.train(X, y, epochs=1000)\n",
    "\n",
    "# Test the neural network\n",
    "probs = net.forward(X)\n",
    "predictions = np.argmax(probs, axis=1)\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4f915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlscripts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
